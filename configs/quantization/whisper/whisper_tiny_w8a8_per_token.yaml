base:
  seed: 42
  precision: "fp16"
  batch_size: 4
  num_workers: 2
  epochs: 1

model:
  name: whisper
  type: Whisper
  path: "openai/whisper-tiny"   # or "openai/whisper-base", etc.
  torch_dtype: auto
  tokenizer_mode: fast
  block_wise_quant: False
  task: "transcribe"                  # or "translate"
  language: "en"
  use_cpu_to_save_cuda_mem_for_catcher: True

data:
  train_manifest: "/path/to/train.json"   # JSONL or manifest with audio paths + transcripts
  val_manifest: "/path/to/val.json"
  sample_rate: 16000
  max_duration: 30   # seconds
  shuffle: True

quant:
  method: SmoothQuant
  weight:
      bit: 8
      symmetric: True
      granularity: per_channel
  act:
      bit: 8
      symmetric: True
      granularity: per_token
  special:
      alpha: 0.75

#save:
#  save_path: "./checkpoints/whisper"
#  save_trans: True
#  save_fake: False
#  save_lightllm: False
#  save_autoawq: False
#  save_vllm: False
#  save_trtllm: False
#  save_mlcllm: False
#  save_lightx2v: False

optim:
  lr: 2e-5
  weight_decay: 0.01
  warmup_steps: 500
  max_grad_norm: 1.0
  scheduler: "linear"

logging:
  log_interval: 50
  eval_interval: 1000

eval:
  type: asr          # ðŸ‘ˆ tells get_eval_list to use ASREval
  name: librispeech_asr
  bs: 1
  download: false
  eval_pos: ["pretrain","fake_quant"]
  path: "librispeech_asr_eval"

calib:
    name: audio
    download: False
    n_samples: 128
    bs: -1
    seq_len: 512
    seed: 0
    path: "librispeech_asr_calib"